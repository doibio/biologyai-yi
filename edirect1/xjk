Author information:
(1)Fred Hutchinson Cancer Research Center, Seattle, WA 98104, USA.

In a previous phase I study, it was concluded that tolerable doses of busulfan 
(BU), cyclophosphamide (CY) and total body irradiation (TBI) were 8 mg/kg, 60 
mg/kg and 12.0 Gy, respectively, for autologous marrow transplant recipients. In 
an attempt to decrease the variability of BU steady-state concentration (Css) 
following oral dosing, a BU dose escalation study based on targeted plasma 
levels was performed in patients receiving autologous transplants for AML or 
syngeneic transplants for CML. In this study, the BU dose was adjusted up or 
down based on observed plasma concentration. All patients received a fixed dose 
of CY 60 mg/kg and TBI of 12 Gy. The first dose level evaluated was 8.6 mg/kg 
with a target BU Css of 511 ng/ml. Eight patients were entered at this level and 
the median BU Css achieved was 441 (range 253-566). One of eight patients 
developed grade 3-4 regimen-related toxicities (RRT). The oral dose of BU for 
dose level II was 10.6 mg/kg with a target Css of 632 ng/ml. Six patients were 
entered at this level and median BU Css achieved was 642 (range 566-674). One of 
six patients developed grade 3-4 RRT. The oral dose for dose level III was 12.6 
mg/kg with a target BU Css of 754 ng/ml. Five patients with AML were entered at 
this dose level and the median plasma BU Css was 733 ng/ml (682-900). Two of 
five (40%) patients at dose level III developed grade 3-4 RRT which was 
considered excessive making dose level II the MTD. This study showed that 
targeted BU Css can reliably be achieved with a bias of -5.23% and mean absolute 
error of 11.3%. Overall, targeting made a -32.5% to 158.3% change in plasma BU 
Css as compared to expected BU Css based on first dose pharmacokinetics if 
targeting were not performed in this study. Thus, targeting avoided much of the 
variability in BU Css seen in other studies and appears to have allowed for an 
increase in oral dosing from 8 mg/kg to 10.6 mg/kg. Despite achieving higher and 
more uniform BU Css, there was no apparent effect on relapse or survival, 
although the number of patients evaluated was small.

PMID: 8722344 [Indexed for MEDLINE]


598. Bone Marrow Transplant. 1996 Apr;17(4):537-42.

Related donor marrow transplant for chronic myeloid leukemia: patient 
characteristics predictive of outcome.

Enright H(1), Daniels K, Arthur DC, Dusenbery KE, Kersey JH, Kim T, Miller WJ, 
Ramsay NK, Vercellotti GM, Weisdorf DJ, McGlave PB.

Author information:
(1)Bone Marrow Transplantation Program, University of Minnesota Health Sciences 
Center, Minneapolis, USA.

Pre-transplant characteristics of 137 consecutive patients (including 103 
patients with one or more features suggesting advanced disease) undergoing 
related donor marrow transplant for chronic myeloid leukemia (CML) were analyzed 
to determine their association with outcome. Multivariate analysis identified 
increased recipient age (relative risk (RR) for patients over 30 years of 
relapse or death 2.37; P = 0.004), and longer interval between diagnosis and 
transplant (RR 1.20; P = 0.0001) as significant adverse influences on 
disease-free survival (DFS). The 5-year DFS for patients transplanted within 1 
year of diagnosis (¿early transplant', n = 71) was significantly higher (51%) 
than that for patients transplanted beyond 1 year from diagnosis ('delayed 
transplant', n = 55) (34%; log rank P = 0.02). For early transplant patients, 
poor prognostic features included myelofibrosis (RR 3.53; P = 0.018), 
splenomegaly (RR 2.22; P = 0.029) and the use of a female donor (RR 3.16; P = 
0.002). The 5-year DFS for patients transplanted within 1 year of diagnosis and 
without signs of advanced disease was 67%. The presence of increasing numbers of 
features suggesting acceleration prior to transplant had a cumulative adverse 
influence of DFS. The risk of relapse (5 year estimate 20%) was also 
independently and significantly increased in association with a longer interval 
from diagnosis to transplant (P = 0.012). Early transplant is an important 
influence on DFS and relapse after related donor transplant therapy for CML, 
although additional patient characteristics influencing outcome can be 
identified and may have cumulative adverse effects.

PMID: 8722351 [Indexed for MEDLINE]


599. Bone Marrow Transplant. 1996 Apr;17(4):643-7.

Polymerase chain reaction is highly predictive of relapse in patients following 
T cell-depleted allogeneic bone marrow transplantation for chronic myeloid 
leukemia.

Mackinnon S(1), Barnett L, Heller G.

Author information:
(1)Bone Marrow Transplant Service Department of Medicine, Memorial Sloan 
Kettering Cancer Center, New York, USA.

In chronic myeloid leukemia (CML) the polymerase chain reaction (PCR) can be 
used to detect minimal residual disease after bone marrow transplantation (BMT). 
Previous studies have shown that PCR positivity is common following BMT. 
However, the clinical significance of this finding for any given individual who 
is PCR positive remains unclear, as many of these patients remain long-term 
disease-free survivors after allogeneic BMT. In the present study, we used PCR 
to detect BCR-ABL mRNA in 144 blood or marrow samples from 36 patients who 
received a T cell-depleted BMT for CML in first chronic phase. Six patients had 
no evidence of PCR-detectable residual disease at any time following transplant. 
The other 30 patients had at least one positive PCR result post-BMT. Once PCR 
positivity was found, it was usually sustained, with only four patients having a 
subsequent PCR negative assay. No patient who had two consecutive PCR-positive 
assays had a return to PCR negativity. None of the six patients with exclusively 
PCR-negative assays have developed either cytogenetic or hematologic relapse at 
a median follow-up of 42 months. Of the 30 patients with at least one 
PCR-positive assay post-BMT, 28 were PCR positive at last follow-up, and 22 have 
progressed to cytogenetic or hematologic relapse. If the PCR-positive assay 
occurred within 24 months of the transplant then the estimated probability of 
progression to cytogenetic or hematologic relapse was 65% at 24 months. Twenty 
of the 26 patients who were studied early (< or = 6 months) after BMT had at 
least one positive PCR assay. Fifteen of the 20 patients who were PCR positive < 
or = 6 months following transplant have progressed to either cytogenetic or 
hematologic relapse resulting in an estimated probability of relapse of 84% at 
24 months. These results indicate that following T cell-depleted BMT for CML in 
first chronic phase, PCR is highly predictive of relapse and may identify a 
cohort of patients in need of therapeutic intervention before the onset of overt 
clinical relapse.

PMID: 8722369 [Indexed for MEDLINE]


600. Genetics. 1996 May;143(1):203-12. doi: 10.1093/genetics/143.1.203.

Change of genetic architecture in response to sex.

Deng HW(1), Lynch M.

Author information:
(1)Department of Biology, University of Oregon, Eugene 97403, USA. 
deng@hgc.sph.uth.tmc.edu

A traditional view is that sexual reproduction increases the potential for 
phenotypic evolution by expanding the range of genetic variation upon which 
natural selection can act. However, when nonadditive genetic effects and genetic 
disequilibria underlie a genetic system, genetic slippage (a change in the mean 
genotypic value contrary to that promoted by selection) in response to sex may 
occur. Additionally, depending on whether natural selection is predominantly 
stabilizing or disruptive, recombination may either enhance or reduce the level 
of expressed genetic variance. Thus, the role of sexual reproduction in the 
dynamics of phenotypic evolution depends heavily upon the nature of natural 
selection and the genetic system of the study population. In the present study, 
on a permanent lake Daphnia pulicaria population, sexual reproduction results in 
significant genetic slippage and a significant increase in expressed genetic 
variance for several traits. These observations provide evidence for substantial 
genetic disequilibria and nonadditive genetic effects underlying the genetic 
system of the study population. From these results, the fitness function of the 
previous clonal selection phase is inferred to be directional and/or 
stabilizing. The data are also used to infer the effects of natural selection on 
the mean and the genetic variance of the population.

DOI: 10.1093/genetics/143.1.203
PMCID: PMC1207254
PMID: 8722775 [Indexed for MEDLINE]601. J Qual Clin Pract. 1996 Mar;16(1):5-15; discussion 17-8.

The challenge of health outcomes.

Hall J(1).

Author information:
(1)Centre for Health Economics Research and Evaluation, University of Sydney, 
NWS, Australia.

The health outcomes initiative can be seen as another passing phase in 
health-care management or taken as a serious challenge to the planning, 
management and evaluation of health services. This paper explores those 
challenges. Implementation of the health outcomes initiative will require the 
application of valid, reliable and appropriately sensitive measures, the use of 
a broad approach to research, development and monitoring in such a way that it 
is an intrinsic part of service delivery, the adoption of policy and practice 
that is firmly based on evidence of outcomes, and the development of an approach 
to research that emphasises generalizability.

PMID: 8723211 [Indexed for MEDLINE]


602. Eur J Gastroenterol Hepatol. 1996 Mar;8(3):225-8. doi: 
10.1097/00042737-199603000-00007.

Effect of cigarette smoking on the course of Crohn's disease.

Breuer-Katschinski BD(1), Holländer N, Goebell H.

Author information:
(1)Department of Gastroenterology, University Hospital Essen, Federal Republic 
of Germany.

OBJECTIVE: It has been shown that smokers are more likely than non-smokers to 
develop Crohn's disease. In order to examine the influence of smoking on the 
course of Crohn's disease, as measured by the risk of surgery, the need for 
surgery was assessed in patients with Crohn's disease.
DESIGN: The course of Crohn's disease was evaluated as to smoking status by life 
table analysis.
SETTING: A tertiary hospital in Essen, Germany.
PATIENTS: The study involved 346 patients with Crohn's disease admitted to 
hospital between 1989 and 1992. Only patients residing in the City of Essen were 
included.
RESULTS: Of the 346 patients, 144 smokers and 143 non-smokers were included in 
the analysis. Overall, 73% of smokers and 39% of non-smokers required one or 
more operations. The corresponding relative risks (RR) and 95% confidence 
intervals were for one operation and more than one operation or no operation at 
all (RR 1.0) 3.9 (2.2-6.9) and 10.8 (5.3-22.1), respectively. There were 
significant differences as to recurrence rates (defined as further surgery after 
first surgery for control of disease) between smokers and non-smokers. For 
smokers the 5- and 10-year recurrence rates were 43% and 64%. For non-smokers 
corresponding recurrence rates were 26% and 33%. For 5- and 10-year recurrence 
rates the RR estimates for smokers versus non-smokers were 3.1 (1.7-5.8) and 6.7 
(2.7-6.8). When stratified by gender, the increased risk for recurrence was 
obvious in both sexes. For the number of cigarettes smoked a dose-response 
effect was obvious in women.
CONCLUSION: These data suggest that the course of Crohn's disease is less 
favourable in smokers than in non-smokers.

DOI: 10.1097/00042737-199603000-00007
PMID: 8724021 [Indexed for MEDLINE]


603. Spine (Phila Pa 1976). 1996 May 1;21(9):1048-54; discussion 1055. doi: 
10.1097/00007632-199605010-00011.

Cost-effectiveness of lumbar discectomy for the treatment of herniated 
intervertebral disc.

Malter AD(1), Larson EB, Urban N, Deyo RA.

Author information:
(1)University of Washington School of Public Health, Seattle, USA.

STUDY DESIGN: A cost-effectiveness analysis of lumbar discectomy based on 
existing efficacy data and newly gathered cost data.
OBJECTIVES: For patients with herniated lumbar discs unresponsive to 
conservative management, surgery relieves pain more rapidly but at higher costs 
than continued medical therapy. We evaluated the cost-effectiveness of lumbar 
discectomy for these patients.
SUMMARY OF BACKGROUND DATA: Effectiveness estimates were based on the results of 
a published trial of 126 herniated disc patients randomized to surgical or 
nonsurgical treatment. Quality of life values were based on a study of 83 
subjects with low back pain. Treatment costs for herniated discs were estimated 
from insurance data for 372 patients treated surgically and 1,803 treated 
medically.
METHODS: Efficacy results were weighted by quality of life values to estimate 
the quality-adjusted benefit of surgery. Cost-effectiveness was calculated in 
dollars per quality-adjusted year of life gained. Supplemental data sources for 
cost and effectiveness provided ranges for sensitivity analyses.
RESULTS: Surgery increased average quality-adjusted life expectancy by 0.43 
years during the decade following treatment, a benefit similar to extending a 
healthy life by 5 months. Reimbursements for surgical patients were $12,550 more 
than for medical patients. Nondiscounted and 5% discounted cost-effectiveness 
were $29,200 and $33,900 per quality-adjusted year of life gained. Supplemental 
analyses confirmed the basecase effectiveness estimates but suggested that the 
cost of discectomy was overestimated. Replacing the main cost estimate with one 
based on HMO patients lowered discectomy's cost to $12,000 per quality-adjusted 
life-year gained.
CONCLUSION: For carefully selected patients with herniated discs, surgical 
discectomy is a cost-effective treatment. Discectomy's favorable 
cost-effectiveness results from its substantial effect on quality of life and 
moderate costs.

DOI: 10.1097/00007632-199605010-00011
PMID: 8724089 [Indexed for MEDLINE]


604. Annu Rev Public Health. 1996;17:25-46. doi:
10.1146/annurev.pu.17.050196.000325.

Disability as a public health outcome in the aging population.

Guralnik JM(1), Fried LP, Salive ME.

Author information:
(1)Epidemiology, Demography, and Biometry Program, National Institute on Aging, 
Bethesda, Maryland 20892, USA.

Improvements in life expectancy in the twentieth century have resulted from 
major declines in mortality at younger ages, but it is less well recognized that 
mortality declines at older ages have also played a substantial role in 
prolonging expectation of life. A person reaching age 65 in 1900 could expect to 
live an additional 11.9 years. Life expectancy at age 65 rose to 14.4 years by 
1960 and then increased by about three years in the next three decades, reaching 
17.5 years in 1992 (56, 70). As a greater proportion of the population survives 
to very old ages, the public health impact of the burden of disease and 
disability and related utilization of medical care and need for supportive and 
long-term care has become an important concern. In particular, the ability of 
the older person to function independently in the community is a critically 
important public health issue. A growing body of research in the last decade has 
addressed the measurement of disability, factors related to its onset, 
consequences of disability, and the potential for preventive interventions. This 
article summarizes the state of the art in these areas and discusses their 
public health relevance.

DOI: 10.1146/annurev.pu.17.050196.000325
PMID: 8724214 [Indexed for MEDLINE]


605. J Clin Gastroenterol. 1996 Apr;22(3):170-3. doi: 
10.1097/00004836-199604000-00003.

Genomania of p53 protein in gastric cancer.

Triantafillou NG, Grosman IM, Verma RS.

The role of oncogenes and tumor suppressor genes in the pathogenesis of gastric 
cancer has recently received considerable attention. p53 is a tumor suppressor 
gene that is essential in the cell cycle; it prevents G1/S phase transition, 
after exposure to ionizing radiation or DNA-damaging chemotherapy. This allows 
the cell to repair its DNA or, if the damage is irreversible, to elicit 
apoptotic cell death. p53 mutations are seen in many human tumors including 
gastric carcinoma. Evidence suggests that mutant p53 is associated with shorter 
life expectancy in gastric, breast, lung, and colorectal cancer. A number of 
studies have shown cellular resistance to chemotherapy in the presence of mutant 
p53. Currently, increasing interest has been devoted to the potential role of 
mutant p53 as a screening tool.

DOI: 10.1097/00004836-199604000-00003
PMID: 8724251 [Indexed for MEDLINE]


606. Leuk Lymphoma. 1996 Jun;22(1-2):71-6. doi: 10.3109/10428199609051730.

Amsacrine and continuous-infusion high-dose cytosine arabinoside as induction 
therapy for patients with newly-diagnosed acute myelogenous leukemia.

Ghaddar HM(1), Pierce S, Kantarjian HM, Freireich EJ, Keating MJ, Estey EH.

Author information:
(1)Department of Hematology, University of Texas M.D. Anderson Cancer Center, 
Houston 77030, USA.

The overall cure rate of adults with newly-diagnosed acute myelogenous leukemia 
(AML) treated with continuous infusion high-dose cytarabine (CIHDAC) is 
comparable to that with standard-dose ara-C plus anthracycline or amsacrine 
(AMSA). We tested whether the addition of AMSA to CIH-DAC improves the outcome 
of adults with untreated AML. 75 patients with untreated AML were treated with 
AMSA (75 mg/m2/day x 4) plus CIHDAC (1.5 g/m2/day x 4) for induction and, if in 
complete remission (CR), early and late intensification. Results were compared 
to those in 129 patients treated on a previous study with CIHDAC alone. The 
principal comparison in both groups was between those 117 patients (AMSA/CIHDAC 
n = 52, CIHDAC n = 65) who met the initial eligibility criteria for the 
AMSA/CIHDAC study (risk of early mortality < or = 1) and who were treated at a 
time when relatively few eligible patients were excluded (19% in the AMSA/CIHDAC 
group, 34% in the CIHDAC group). There was no difference between regimens in CR 
rate, remission duration, or survival in this cohort. When attention was turned 
to all 204 patients, outcome was superior with AMSA/CIHDAC very largely as a 
result of outcome in patients with APL. Aside from these patients, addition of 
amsacrine to CIHDAC did not appear to be productive.

DOI: 10.3109/10428199609051730
PMID: 8724530 [Indexed for MEDLINE]


607. Leuk Lymphoma. 1996 Jun;22(1-2):137-42. doi: 10.3109/10428199609051741.

CD5-expressing B-cell lymphomas/leukemias: relatively high frequency of CD5+ 
B-cell lymphomas with an overall poor prognosis in Nagasaki Japan.

Kamihira S(1), Hirakata Y, Atogami S, Sohda H, Tsuruda K, Yamada Y, Tomonaga M.

Author information:
(1)Department of Laboratory Medicine, Nagasaki University School of Medicine, 
Japan.

To characterize CD5+ B-cell neoplasms in Japan, where chronic lymphocytic 
leukemia (CLL) is rare and of different subtypes in comparison with Western 
countries, we collected 58 cases of CD5+ B-cell lymphomas/leukemias and analyzed 
their clinicopathologic features. According to the French-American-British (FAB) 
and standard histologic classification, the cases corresponded to small 
lymphocytic lymphoma (SLL, group I; n = 22, consisting of CLL, n = 10, CLL/PL, n 
= 3, and CLLmixed, n = 7); intermediate differentiated lymphoma/mantle cell 
lymphoma (IDL/MCL, group II, n = 18); and others with CD5-positive lymphomas 
(group III, n = 18). The CD5+ B-cell lymphomas showed morphologic and prognostic 
variability among the three groups. The clinical and immunophenotypic features 
were remarkably consistent in leukemic disease being seen in 73% of all cases, 
splenomegaly in 63%, and intense CD19, CD20, surface membrane immunogobulin M 
(SmIgM) or SmIgM and SmIgD, light-chain expression, and no CD10 expression. The 
median survival time of groups I, II, and III was 7.8, 3.3, and 0.8 years, 
respectively. These findings suggest that CD5 antigens may serve as valid 
markers for the prognosis and clinical features of B-cell lymphomas and that 
CD5+ B-cell lymphomas with an overall poor prognosis occurs at a relatively high 
frequency in Japan. This also suggests that a combination of immunophenotypic 
and morphologic features is of value for characterizing CD5+ B-cell neoplasms.

DOI: 10.3109/10428199609051741
PMID: 8724541 [Indexed for MEDLINE]


608. Minerva Chir. 1995 Dec;50(12):1069-72.

[Synchronous carcinoma of the colon and rectum].

[Article in Italian]

La Ganga V(1), Cavanna A, Di Ponzio D, Montobbio A.

Author information:
(1)Divisione di Chirurgia Generale, Ospedale Civile Ovada, Alessandria.

The incidence of synchronous carcinoma of colon-rectus is rising in relation to 
a greater oncogenic environmental charge and increased average life expectancy. 
There is also a risk of not recognising the disease (especially small carcinoma 
or multicentric neoplasm). After a Literature review, two clinical cases are 
described by the authors. They recommend an extensive use of preoperative 
colonoscopy and a careful intraoperative exploration of the viscera. It is also 
important that patients undergo periodical postoperative endoscopic controls.

PMID: 8725065 [Indexed for MEDLINE]


609. Am J Med Genet. 1996 May 31;67(3):289-300. doi: 
10.1002/(SICI)1096-8628(19960531)67:3<289::AID-AJMG5>3.0.CO;2-I.

Genetic heterogeneity in catatonic schizophrenia: a family study.

Beckmann H(1), Franzek E, Stöber G.

Author information:
(1)Department of Psychiatry, University of Wuerzburg, Germany.

In family study concentrating on 139 probands with chronic DSM-III-R 
schizophrenia, catatonic type, 83 probands (41 women, 42 men) met the criteria 
for periodic catatonia and 56 probands (14 women, 42 men) for systematic 
catatonia according to the Leonhard classification. The reliability and 
stability of this subclassification were tested by 2 experienced psychiatrists 
working independently of each other. Both diagnosticians were kept blind as to 
the probands' family history. The 139 probands had a total of 543 first-degree 
relatives. Only those hospitalized for schizophrenia were allocated to the group 
of afflicted family members. Diagnostic reliability was kappa statistic 0.93 and 
diagnostic stability during catamnesis reached 97% and kappa of 0.93. Life-table 
analyses revealed that the age-corrected risks were significantly different in 
periodic and systematic catatonia. In systematic catatonia mothers had a risk of 
6.8%, fathers 2%, and randomly selected sibs 3%. IN periodic catatonia an excess 
of homologous psychoses was apparent: There was a risk of 33.7% for mothers, 
15.4% for fathers, and 24.4% for sibs. The quota of afflicted parents (33 of 
161) was higher than that of sibs (26 of 162). In periodic catatonia, 59% of the 
families were multiple afflicted with pronounced unilineal vertical 
transmission. In 10% of the families 3 successive generations suffered from the 
disease and were treated in hospital. The results of the study led to the 
following hypotheses: Periodic and systematic catatonia are valid subgroups of 
DSM-III-R schizophrenia. In systematic catatonia heritability is very low. 
Periodic catatonia is a familial disorder. Homogeneity of familial psychoses and 
unilineal vertical transmission with anticipation are consistent with a major 
gene effect. Periodic catatonia seems to be a promising candidate for molecular 
genetic evaluation.

DOI: 10.1002/(SICI)1096-8628(19960531)67:3<289::AID-AJMG5>3.0.CO;2-I
PMID: 8725746 [Indexed for MEDLINE]


610. Am J Ind Med. 1996 Apr;29(4):421-4. doi: 
10.1002/(SICI)1097-0274(199604)29:4<421::AID-AJIM30>3.0.CO;2-1.

NIOSH research initiatives to prevent back injuries to nursing assistants, 
aides, and orderlies in nursing homes.

Collins JW(1), Owen BD.

Author information:
(1)Division of Safety Research, National Institute for Occupational Safety and 
Health, Morgantown, WV 26505-2845, USA.

Over the past 100 years, advances in nutrition, modern medicine, public health, 
and a multitude of public health improvements have increased the life expectancy 
of U.S. residents. The fact that Americans are living longer has resulted in 
extensive growth in our elderly population and a rapid employment growth that 
delivered about 2 million new jobs between 1980 and 1989 in the health care 
workforce. The Bureau of Labor Statistics Injury and Illness Data for nursing 
homes rose from 10.7 to 18.6 injuries or illnesses per 100 full-time workers 
between 1980 and 1992. The injury and illness rates among nursing home workers 
are partly due to the physical stress of providing round-the-clock assistance 
with the basic activities of daily living, such as getting in and out of a bed 
or chair, as well as bathing and toileting. The National Institute for 
Occupational Safety and Health (NIOSH) is conducting a series of research 
studies to identify strategies to reduce the risk of musculoskeletal injuries to 
workers in nursing homes. NIOSH has funded two laboratory evaluations of 
resident transferring methods and one field study in an actual nursing home. The 
purpose of this paper is to describe the key findings from past NIOSH research 
initiatives and to present an overview of future research.

DOI: 10.1002/(SICI)1097-0274(199604)29:4<421::AID-AJIM30>3.0.CO;2-1
PMID: 8728153 [Indexed for MEDLINE]


611. Perit Dial Int. 1996;16 Suppl 1:S330-2.

Peritoneoscopic placement of Swan neck peritoneal dialysis catheters.

Copley JB(1), Lindberg JS, Back SN, Tapia NP.

Author information:
(1)Department of Medicine, Ochsner Clinic, New Orleans, Louisiana 70121, USA.

Peritoneoscopic placement of peritoneal dialysis catheters, although 
accomplished in only about 10% of dialysis centers, is a nonsurgical technique 
that fulfills requirements for safety and dependability. Over a 40-month period, 
136 catheters were placed with the peritoneoscope, 135 of which were 
double-cuffed, Swan neck curled catheters, with a uniform radiopaque stripe. 
Patients were followed longitudinally for outcome. Catheters were placed in 44 
diabetic patients, 1 human immunodeficiency virus (HIV)-positive patient, and 18 
morbidly obese patients. No complications occurred as a direct result of 
placement. Catheters were used, on average, nine days after placement (many on 
days 1 to 4) usually with 1.5 to 2 L exchanges. With 1183 patient-months' 
experience, complications were few: 28 patients experienced catheter-related 
infections, and there were five leaks that resolved with supine, low-volume 
dialysis for several days. Leakage did not correlate with time of usage after 
placement. Of ten outflow/mechanical problems that required catheter removal, 
nine involved catheter migration, probably due to lack of attention during 
placement to orientation of the radiopaque stripe. One was due to a 
preperitoneal placement early in this institution's experience with the 
peritoneoscope. Five of the migrated catheters were removed and then 
successfully replaced with the peritoneoscope at the same sitting. Four patients 
requested surgical removal and replacement. Sixteen catheters were removed 
because of catheter-related infections: five refractory Staphylococcus aureus, 
six Pseudomonas aeruginosa, two fungal, two Serratia species, and one 
Mycobacterium chelonei. Actuarial life-table analysis showed that at the end of 
the 40-month follow-up, 62% of the catheters were expected to survive. Because 
more than 50% survived, median catheter survival could not be calculated. The 
adverse responses were removal because of infection or catheter migration. 
Peritoneal dialysis catheter implantation with the peritoneoscope represents a 
safe and dependable method for catheter placement. Literature review and 
comparison indicate that catheter-related complications are fewer and catheter 
longevity is better with peritoneoscopic placement than with surgical placement. 
Our experience with prompt postplacement utilization suggests the need for 
further evaluation of catheter break-in procedure with the peritoneoscope.

PMID: 8728218 [Indexed for MEDLINE]


612. Rev Med Chil. 1995 Sep;123(9):1137-49.

[Advances in the treatment of tachiarrhythmias: role of nonpharmacological 
methods].

[Article in Spanish]

Asenjo RG(1), Vidaillet H Jr, Hayes JJ, Smith PN, Rosselot EJ.

Author information:
(1)Centro Cardiovascular, Hospital Clínico de la Universidad de Chile, Santiago.

Nonpharmacological methods are a novel therapeutic option for tachiarrhythmias. 
Transcatheter ablation or surgery can cure many arrhythmias, avoiding the 
collateral effects of antiarrhythmic drugs. Likewise, implantable 
defibrillators, have changed life expectancy of patients with high risk 
arrhythmias or sudden death survivors. However, the high cost and sophistication 
of these methods, preclude their widespread use, thus limiting the number of 
patients that can be benefited. This article reviews the main nonpharmacological 
techniques for treatment of arrhythmias, their results and complications.

PMID: 8728739 [Indexed for MEDLINE]


613. Zhonghua Liu Xing Bing Xue Za Zhi. 1995 Dec;16(6):362-4.

[Analysis on the health status of residents from Diseases Surveillance Points in 
Gansu Province].

[Article in Chinese]

Meng L(1), Bai L, Hao EH.

Author information:
(1)Gansu Provincial Hygiene and Epidemic Prevention Station, Lan zhou.

We have surveyed a population size of 6633315 from Diseases Surveillance Points 
(DSP) system in Gansu province for the last eleven years. The annual birth rate 
was 18.20% with an annual standard mortality rate 545.80/10(5). The annual 
standard mortality for male and female were 607.53/10(5) and 483.29/10(5) 
respectively. The major causes of death were Respiratory system diseases, 
Cardiovascular diseases, Neoplasms, Injuries, Digestive system diseases, 
Pediatric diseases, Infectious diseases in sequence. In eleven years, there 
seemed to be a rising trend in the mortalities of following diseases as: 
Cerebrovascular diseases, Ischemic heart diseases, Rheumatic fever and heart 
disease, Lung Cancer, Liver Cancer, Cancer of the Esophagus, Intestinal cancer, 
Cervical cancer, Injury, Congenital abnomalities, to different degrees. However, 
an obvious descending trend on the morbidity and mortality of infectious 
diseases was moticed. The average life expectancy was 71.05 years in DSP, with 
male 69.57 years, and female 72.72 years. Diseases with higher PYLL were 
Injuries, Neoplasms, Respiratory system diseases and the like. Data suggested 
not only the prevention andcontrol of infectious diseases, but also the 
surveillance of injuries and the prevention and control of chronic diseases 
should be strengthened.

PMID: 8728958 [Indexed for MEDLINE]


614. Lipids. 1996 Mar;31 Suppl:S283-6. doi: 10.1007/BF02637092.

Characteristics of fats in Japanese diets and current recommendations.

Sugano M(1).

Author information:
(1)Laboratory of Food Science, Kyushu University School of Agriculture, Fukuoka, 
Japan.

Although there is no firm evidence to support the "ideal" or even "appropriate" 
healthy level of dietary fat, the habitual fat consumption pattern in Japan 
seems to be a criterion for the recommended allowance both in the quantitative 
and qualitative points of view as judged from the life expectancy and the 
incidence of degenerative diseases. The new recommended dietary allowance of 
Japan, fifth revision effective for five years starting in 1995, adopted dietary 
fat levels of 20-25 energy percent, the ratio of saturated, monounsaturated, and 
polyunsaturated fatty acids at 1:1.5:1 and the ratio of n-6/n-3 at 4. The 
recommended fat level is similar to that previously consumed in Japan, and is 
even lower than that in diets used to treat hyperlipidemia in Western countries, 
current recommendations in those countries being 30 energy percent fat. 
Convincing data for the beneficial effects of n-3 polyunsaturated fatty acids on 
human health, in particular for healthy people, have been presented in only a 
few reports. However, the recommended n-6/n-3 ratio of 4 seems reasonable 
compared with the ratio of around 10 in other developed countries. In this 
context, it is more important to fully understand the nutritional and 
physiological roles of fat in healthy people rather than in those with chronic 
disease. At present, the low-fat dietary pattern in Japan appears to be a 
healthy way of eating.

DOI: 10.1007/BF02637092
PMID: 8729135 [Indexed for MEDLINE]


615. Popul Trends. 1996 Spring;(83):17-24.

Which areas are healthiest?

Charlton J.

This article compares mortality rates by geography and over time. This is done 
by analysing, for England and Wales, mortality data from 1981 to 1992 by cause, 
local authority, and ward, using the new OPCS area classifications, and the 
urban/rural categorisation of 1991 Census enumeration districts based on land 
use. The proportion of babies who in 1990-92 were lightweight at birth was also 
examined. Urban areas (particularly purpose-built inner city estates and 
deprived industrial areas) tend to be the least healthy. Rural and prosperous 
areas are the most healthy, and the biggest health gains have been made in 
these. Based on 1992 mortality rates, out of every 100 boys born in 'Ports and 
industry' areas, 16 would survive to age 85 whereas 24 would do so in the 'Most 
prosperous' areas. The corresponding figures for girls were 33 and 43. The 'Most 
prosperous' areas also had the most similar male and female life expectancies, 
with the difference narrowing throughout the period 1981-1992. In 1990-92 people 
in 'Ports and industry' areas had the highest male mortality levels for 
malignant neoplasms, lung cancer, circulatory diseases, ischaemic heart disease 
and cerebrovascular disease. People in 'Inner London' had the highest levels for 
respiratory diseases and injury and poisoning.

PMID: 8729792 [Indexed for MEDLINE]


616. Popul Trends. 1996 Spring;(83):25-36.

The proportion of married couples who divorce: past patterns and current 
prospects.

Haskey J.

This article provides estimates of the proportions of marriages which ended in 
divorce for the different groups of couples who have married since the 1950s. 
Over one quarter of all couples who married in the late 1970s and early 1980s 
had divorced by the end of 1994. As well as giving the overall proportion of 
couples married in a given year who subsequently divorced, estimates are 
provided of the corresponding proportions for different subsets of those 
couples--according to each partner's marital status before marriage, and age at 
marriage. For some of the higher risk groups--bachelors and spinsters who 
married as teenagers and divorced men and women who remarried in their early 
twenties--the proportions who had divorced by 1994 had reached over 40 per cent, 
and in some cases just over 50 per cent, amongst those who had married between 
the mid-1960s and the mid-1970s. Finally, a life table analysis is carried out 
to estimate the proportion of marriages which would end in divorce were the 
duration--specific divorce rates to remain unchanged at their 1993/94 levels. On 
this basis, two in five marriages would ultimately end in divorce; just under 
one half of couples would celebrate their silver wedding, whilst the average 
length of marriage would be 26 years.

PMID: 8729793 [Indexed for MEDLINE]


617. Baillieres Clin Haematol. 1996 Mar;9(1):147-59. doi: 
10.1016/s0950-3536(96)80041-2.

Treatment of the elderly patient with acute myeloid leukaemia.

Löwenberg B(1).

Author information:
(1)Department of Hematology, Erasmus University Hospital, Rotterdam, The 
Netherlands.

Individuals of 60 years living in western countries generally have a mean life 
expectancy of 20 years at least. Therefore, when aged individuals present with 
AML, it is a necessity and a challenge to treat them as efficiently as possible. 
AML is mainly a disease of the elderly and accounts for more than 50% of its 
incidence among the general population. The treatment of older individuals with 
AML has remained difficult and its success is still limited. While in adults 
with AML of less than 60 years complete responses above 65% and survival rates 
of 35% are commonly obtained, progress in the treatment of elderly patients has 
been relatively small. As of today, approximately 50% of older patients may be 
induced into remission with chemotherapy, and, among these complete responders, 
only approximately 1 in 10 will survive free of leukaemia beyond 4 years after 
diagnosis. In fact, on one hand, these results represent the rationale and 
motivation for offering chemotherapy to the older population. On the other hand, 
they emphasize that major obstacles to better cure rates still exist. These 
stumbling blocks apparently relate to the restricted tolerance of older subjects 
to the exposure of chemotherapy and probably also a greater probability of 
unresponsiveness of the leukaemia to cytotoxic therapy. The haematopoietic 
growth factors still hold some promise and may improve outcome, but for the time 
being there is insufficient direct evidence to indicate a defined and 
established role. It is evident that new avenues should be pursued and trials 
specifically designed for elderly people with AML be conducted. These trials 
would need to address questions related to the choice of chemotherapeutic drugs 
(e.g. idarubicin versus mitoxantrone), their dose and schedule selection, the 
use of multidrug resistance modulators (to overcome intrinsic drug 
non-responsiveness), and the optimal clinical use of haematopoietic growth 
factors, including thrombopoietin. Since trials addressing specific questions 
regarding the development of treatment of elderly patients with AML have 
remained scarce, the initiation of these studies is sorely needed. One may hope 
that these clinical trials will provide some of the necessary answers and new 
clues, and will be useful to advance future therapy of elderly AML patients.

DOI: 10.1016/s0950-3536(96)80041-2
PMID: 8730555 [Indexed for MEDLINE]


618. World J Urol. 1996;14(2):73-7. doi: 10.1007/BF00182561.

The modified rectal bladder in children: long-term follow-up.

Dawaba MS(1), Dawood A, Ghoneim MA.

Author information:
(1)Urology and Nephrology Center, Mansoura, Egypt.

The criteria for evaluation of urinary diversion procedures in children must be 
strict since their life expectancy is long. Our experience with the modified 
rectal bladder in children with considerable follow-up periods is reported 
herein. All patients were continent by day and night. Urography studies revealed 
a normal upper tract in all cases. Three early complications were encountered 
among patients who had a submucous tunnel reimplantation. Reflux to the proximal 
colon or the kidneys was not demonstrated. The metabolic status and growth-rate 
patterns of these patients were within normal limits without alkaline therapy. 
All urine samples aspirated from the renal pelves were sterile. We conclude that 
a modified rectal bladder with a second ileal intussusception valve is the 
operation of choice whenever urinary diversion in children is indicated.

DOI: 10.1007/BF00182561
PMID: 8731121 [Indexed for MEDLINE]


619. Rev Rhum Engl Ed. 1996 Mar;63(3):196-200.

Results of surgery for lumbar spinal stenosis in patients aged 80 years or more. 
A retrospective study of thirty-four cases.

Ishac R(1), Alhayek G, Fournier D, Mercier P, Guy G.

Author information:
(1)Department of Neurosurgery, Teaching Hospital, Angers, France.

As life expectancy increases and spinal imaging techniques improve, surgery is 
being increasingly viewed as a therapeutic alternative for symptomatic lumbar 
spinal stenosis in patients older than 80 years. Thirty-four patients (21 men 
and 13 women) who had surgery for lumbar spinal stenosis in our department 
between 1979 and 1994 were studied retrospectively. The most common initial 
symptoms were walking-related disorders (n = 29) and sciatica or femoral 
neuralgia (n = 34). All 34 patients underwent laminectomy at one or more levels. 
Ten patients also had a herniated disk. There were no deaths and only two 
patients had serious complications (persistent foot drop in one and left-sided 
hemiplegia in the other). Results were evaluated immediately after surgery and 
after three and 12 months. The overall result on pain and walking-related 
disorders was good in 53% of cases, acceptable in 32%, and poor in 15%. Our data 
suggest that surgery is a reasonable alternative in symptomatic elderly patients 
who are in good general health. Satisfactory results can be obtained although 
disabling complications can occur.

PMID: 8731237 [Indexed for MEDLINE]


620. Rev Saude Publica. 1995 Oct;29(5):403-14. doi:
10.1590/s0034-89101995000500011.

[The Brazilian economy in the 80's and its impact on the living conditions of 
the population].

[Article in Portuguese]

Ometto AM(1), Furtuoso MC, da Silva MV.

Author information:
(1)Departamento de Economia Doméstica da Escola Superior de Agricultura Luiz de 
Queiroz (ESALQ/USP), Piracicaba, SP, Brasil.

In the 80's the Brazilian economy underwent one of the most severe crises of its 
history, resulting in the stagnation of the gross national product and inflation 
rates such as never previously reported. Despite this unfavorable scenario 
social indicators have presented a positive evolution. This work shows that 
although the Brazilian family has adopted the over-use of the family work force 
as a strategy for facing this crisis on the work market, the evolution of both 
income and poverty in that period were poor. The increase of expenses and the 
transformation of the forms of implementation of public policy in the health and 
nutrition areas are shown to be decisive factors in the performance of social 
indicators.

DOI: 10.1590/s0034-89101995000500011
PMID: 8731282 [Indexed for MEDLINE]


621. J Intellect Disabil Res. 1996 Apr;40 ( Pt 2):180-2. doi: 
10.1046/j.1365-2788.1996.742742.x.

Life expectancy of mentally retarded hemiplegics.

Jancar J(1), Sabogal NM, Wiley YV.

Author information:
(1)Stoke Park Hospital, Stapleton, Bristol, England.

Sixty-four mentally retarded people with hemiplegia (35 females and 29 males), 
first recorded in 1963, were re-examined 30 years later for life expectancy. 
Detailed physical and mental states, lengths of hospital stays and other 
information were noted. Recent advances in diagnosis and prognosis of 
hemiplegics were included. The results of the study indicate that, with special 
provisions available, people with hemiplegia have the prospect of reaching 
pensionable age and beyond: the oldest female is 85 and the oldest male 76 years 
of age.

DOI: 10.1046/j.1365-2788.1996.742742.x
PMID: 8731476 [Indexed for MEDLINE]


622. Eur Heart J. 1996 Apr;17 Suppl B:2-7. doi: 10.1093/eurheartj/17.suppl_b.2.

Pathophysiological targets for beta-blocker therapy in congestive heart failure.

Just H(1).

Author information:
(1)Medizinische Universitätsklinik Freiburg im Breisgau Abteilung Innere Medizin 
III/Kardiologie, Angiologie, Germany.

The treatment of congestive heart failure has seen considerable changes: while 
treatment with diuretics, digitalis glycosides and vasodilators has remained the 
mainstay of therapy, recently neurohumeral inhibition has been developed as an 
important principle: ACE-inhibitors have been shown to significantly improve 
quality of life and exercise performance and to substantially reduce mortality. 
Beta-blockers have been employed with increasing success mainly in congestive 
heart failure due to dilated idiopathic cardiomyopathy, in which a significant 
improvement in symptoms and life expectancy has been demonstrated. However, the 
precise mechanisms by which beta-blockade improves congestive heart failure 
remain to be elucidated. In addition to direct sympathoadrenal inhibition, 
reduction of heart rate may also play a major role in the therapeutic efficacy 
of beta-blockade in congestive heart failure. In the normal human heart increase 
in heart rate is accompanied by an increase in myocardial contractile 
performance (Bowditch-Treppe phenomenon). In chronic heart failure the 
myocardium undergoes a phenotype change which includes alterations of the 
activity of enzymes regulating calcium homoeostasis. The sarcoplasmic reticulum 
calcium ATPase (SERCA) is depressed both in function, as well as in expression. 
At the same time the sarcolemmal sodium-calcium exchanger is increased both in 
function and in expression. The result is a characteristic change in calcium 
homoeostasis with decreased diastolic uptake of calcium into the sarcoplasmic 
reticulum with subsequently reduced calcium release during the next systole, 
resulting in reduced contractile performance. At the same time increased 
capacity of the sodium-calcium exchanger extrudes intracellular calcium ions to 
the extra-cellular space, thereby rendering these ions unavailable for the 
contractile cycle. A result of these, seemingly specific, phenotype changes is 
an alteration of the force/frequency relationship. Instead of increasing force 
of contraction with increasing heart rates, in the chronically failing 
myocardium the contractile performance declines with increasing heart rates and 
only improves with decreasing rates. Optimal performance can be seen at heart 
rates as low as 30 beats.min. Studies employing photoluminescence markers of 
free cytosolic calcium, such as aequorin, have shown that there is a direct 
correlation between free cytosolic calcium and contractile performance at 
different levels of heart rate. It is likely, therefore, that the heart rate 
reduction with beta-blockade may provide the major explanation for the 
therapeutic benefits of beta-blockade in chronic congestive heart failure.

DOI: 10.1093/eurheartj/17.suppl_b.2
PMID: 8733064 [Indexed for MEDLINE]


623. Eur Heart J. 1996 Apr;17 Suppl B:43-56. doi:
10.1093/eurheartj/17.suppl_b.43.

Congestive heart failure. Towards a comprehensive treatment.

Taylor SH(1).

Author information:
(1)University Department of Cardiovascular Studies, General Infirmary, Leeds, 
UK.

Heart failure constitutes an increasing health hazard with major demands on 
health care resources. Recent major advances in drug treatment have yet to be 
translated into increased survival of heart failure patients in the community at 
large. Failure of diagnosis is a major factor in delaying early and adequate 
treatment. Echocardiography probably provides the most reliable and inexpensive 
instrument to confirm the diagnosis and pinpoint the mechanical components of 
the syndrome. The targets for therapeutic intervention may be categorized (i) 
haemodynamic, neuroendocrine and metabolic disorders (ii) symptoms and quality 
of life, (iii) morbidity and mortality risks. Symptoms and quality of life are 
the prime concerns of the physician in the treatment in the individual patient. 
Selection of anti-heart failure drugs used should be based on knowledge of the 
impact on the pathophysiological disorders and on the morbidity and mortality 
risks. Diuretics, vasodilators and ACE-inhibitors are now accepted as standard 
treatment, particularly when used in combination. Controversy continues to 
surround the efficacy of digitalis glycosides; they improve symptoms in some 
patients but their impact on morbidity and mortality risks is still uncertain. 
Even with standard treatments, may practical therapeutic questions remain, one 
of which is what is the most efficacious dose of each anti-heart failure drug 
which, when used in combination, will give the maximum improvement in quality of 
life and greatest extension of survival? Despite available treatment with 
diuretics, digitalis, vasodilators and ACE-inhibitors, the morbidity and 
mortality risks of congestive heart failure remain high. None of these drug 
groups significantly modulates the excessive excitation of the sympathoadrenal 
system, one of the two major neuroendocrine hazards of heart failure. For this 
reason, amongst the many newer drugs in development, the beta-adrenoceptor 
antagonists hold considerable promise as the next step towards a more 
comprehensive treatment of congestive heart failure.

DOI: 10.1093/eurheartj/17.suppl_b.43
PMID: 8733071 [Indexed for MEDLINE]


624. Health Econ. 1996 Mar-Apr;5(2):99-103. doi: 
10.1002/(SICI)1099-1050(199603)5:2<99::AID-HEC193>3.0.CO;2-N.

And now for vertical equity? Some concerns arising from aboriginal health in 
Australia.

Mooney G.

Comment on
    Health Econ. 1993 Dec;2(4):295-302.

DOI: 10.1002/(SICI)1099-1050(199603)5:2<99::AID-HEC193>3.0.CO;2-N
PMID: 8733102 [Indexed for MEDLINE]


625. Health Econ. 1996 Mar-Apr;5(2):141-54. doi: 
10.1002/(SICI)1099-1050(199603)5:2<141::AID-HEC189>3.0.CO;2-N.

The time trade-off method: results from a general population study.

Dolan P(1), Gudex C, Kind P, Williams A.

Author information:
(1)University of Newcastle, UK.

An important consideration when establishing priorities in health care is the 
likely effects that alternative allocations of resources will have on 
health-related quality-of-life (HRQoL). This paper reports on a large-scale 
national study that elicited the relative valuations attached by the general 
public to different states of health (defined in HRQoL terms). Health state 
valuations were derived using the time trade-off (TTO) method. The data from 
3395 respondents were highly consistent, suggesting that it is feasible to use 
the TTO method to elicit valuations from the general public. The paper shows 
that valuations for severe health states appear to be affected by the age and 
the sex of the respondent; those aged 18-59 have higher valuations than those 
aged 60 or over and men have higher valuations than women. These results 
contradict those reported elsewhere and suggest that the small samples used in 
other studies may be concealing real differences that exist between population 
sub-groups. This has important implications for public policy decisions.

DOI: 10.1002/(SICI)1099-1050(199603)5:2<141::AID-HEC189>3.0.CO;2-N
PMID: 8733106 [Indexed for MEDLINE]


626. Arch Mal Coeur Vaiss. 1996 Feb;89 Spec No 1:141-7.

Implantable cardioverter-defibrillator: present and future indications.

Block M(1), Scheld H, Breithardt G.

Author information:
(1)Department of Cardiology-Angiology, Hospital of the Westfälische 
Wilhelms-University of Münster, Germany.

Indications for of automatic cardioverter-defibrillators of automatic in 
patients with ventricular tachyarrhythmias have changed since the publications 
of first guidelines in 1991. Less invasive surgical approaches reduced the 
perioperative mortality. Tiered therapy devices improved the quality of life by 
reducing appropriate and inappropriate shocks. A low annual incidence of sudden 
death with implantable cardioverter defibrillators and frustrating results with 
antiarrhythmic drugs caused an extension of implantable 
cardioverter-defibrillator indications. Despite the absence of prospective 
studies implantable cardioverter-defibrillators have become a first line 
treatment for patients with ventricular tachyarrhythmias which are not due to 
acute myocardial infarction. In cardiac arrest survivors implantable 
cardioverter-defibrillator therapy has become the gold standard due to the low 
annual incidence of sudden death seen in implantable cardioverter-defibrillator 
patients. The results of ongoing prospective studies comparing implantable 
cardioverter-defibrillator therapy to antiarrhythmic drugs have to be awaited 
and will influence tomorrow's indications for implantable 
cardioverter-defibrillator therapy in patients with documented ventricular 
tachyarrhythmias. Additionally, studies evaluating prophylactic implantable 
cardioverter-defibrillator implantations in patients at high risk for 
ventricular tachyarrhythmias might expand indications for implantable 
cardioverter-defibrillator therapy.

PMID: 8734176 [Indexed for MEDLINE]


627. Int J Neurosci. 1996 Apr;85(3-4):195-220. doi: 10.3109/00207459608986683.

Diagnosis, physiology, pathology and rehabilitation of traumatic brain injuries.

Berker E(1).

Author information:
(1)Psychology Department, Western Michigan University, Kalamazoo 49008, USA.

Accumulating clinical and experimental studies continue to elucidate and further 
